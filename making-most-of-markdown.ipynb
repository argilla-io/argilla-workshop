{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Most of Markdown within Argilla TextFields\n",
    "\n",
    "## Introduction\n",
    "\n",
    "As you may have noticed, Argilla supports Markdown within its text fields. This allows you to add formatting to your text, such as **bold** or *italic* text, or even [links](https://www.google.com). Additionally, this also allows you to add all HTML content, such as images, videos, and even iframes, which is a powerfull tool to have at your disposal.\n",
    "\n",
    "Within this notebook, we will go over the basics of Markdown, and how to use it within Argilla.\n",
    "\n",
    "- multi-modality\n",
    "    - image\n",
    "    - video\n",
    "    - audio\n",
    "- table\n",
    "- exploiting displacy\n",
    "  - ner\n",
    "  - relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "We will be working with builtin Python libraries, as well as the `argilla` library. Additionally, we will use a unstructored document processor with a externally callable public API (to avoid overhead). This tool is called [IBM Deep Search](https://github.com/DS4SD/deepsearch-toolkit) but for a fully open source alternative, I recommend taking a look at [Unstructured](https://unstructured.io). To install the latter, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Requirement already satisfied: argilla==1.17 in ./.venv/lib/python3.10/site-packages (1.17.0)\n",
      "Requirement already satisfied: httpx<0.24,>=0.15 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (0.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (23.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (1.14.1)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (1.2.14)\n",
      "Requirement already satisfied: backoff in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (2.2.1)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.10.7 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (1.10.13)\n",
      "Requirement already satisfied: monotonic in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (1.6)\n",
      "Collecting typer<0.8.0,>=0.6.0\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/typer/0.7.0/typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: numpy<1.24.0 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (4.66.1)\n",
      "Requirement already satisfied: rich!=13.1.0 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (13.0.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from argilla==1.17) (1.5.3)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx<0.24,>=0.15->argilla==1.17) (1.3.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in ./.venv/lib/python3.10/site-packages (from httpx<0.24,>=0.15->argilla==1.17) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in ./.venv/lib/python3.10/site-packages (from httpx<0.24,>=0.15->argilla==1.17) (0.16.3)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx<0.24,>=0.15->argilla==1.17) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.10/site-packages (from pandas<2.0.0,>=1.0.0->argilla==1.17) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas<2.0.0,>=1.0.0->argilla==1.17) (2023.3.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.10/site-packages (from pydantic<2.0,>=1.10.7->argilla==1.17) (4.8.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in ./.venv/lib/python3.10/site-packages (from rich!=13.1.0->argilla==1.17) (2.16.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in ./.venv/lib/python3.10/site-packages (from rich!=13.1.0->argilla==1.17) (0.9.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.venv/lib/python3.10/site-packages (from typer<0.8.0,>=0.6.0->argilla==1.17) (8.1.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla==1.17) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./.venv/lib/python3.10/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla==1.17) (4.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.0.0->argilla==1.17) (1.16.0)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx<0.24,>=0.15->argilla==1.17) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla==1.17) (1.1.3)\n",
      "Installing collected packages: typer\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepsearch-toolkit 0.29.1 requires typer[all]<0.10.0,>=0.9.0, but you have typer 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typer-0.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.10/site-packages (2.14.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./.venv/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in ./.venv/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (3.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Requirement already satisfied: spacy in ./.venv/lib/python3.10/site-packages (3.7.2)\n",
      "Collecting spacy-transformers\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/spacy-transformers/1.3.2/spacy_transformers-1.3.2-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.venv/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.10/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./.venv/lib/python3.10/site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from spacy) (63.2.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./.venv/lib/python3.10/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.10/site-packages (from spacy) (1.10.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
      "  Downloading https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/spacy-alignments/0.9.1/spacy_alignments-0.9.1-cp310-cp310-macosx_11_0_arm64.whl (317 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers<4.35.0,>=3.4.0\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/transformers/4.34.1/transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "Collecting torch>=1.8.0\n",
      "  Downloading https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/torch/2.1.0/torch-2.1.0-cp310-none-macosx_11_0_arm64.whl (59.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Collecting sympy\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/sympy/1.12/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx\n",
      "  Downloading https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/networkx/3.2/networkx-3.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers) (2023.6.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=1.8.0->spacy-transformers) (3.12.4)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/safetensors/0.4.0/safetensors-0.4.0-cp310-cp310-macosx_11_0_arm64.whl (425 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.4/425.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.15,>=0.14\n",
      "  Downloading https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/tokenizers/0.14.1/tokenizers-0.14.1-cp310-cp310-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers<4.35.0,>=3.4.0->spacy-transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/regex/2023.10.3/regex-2023.10.3-cp310-cp310-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m280.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.10/site-packages (from transformers<4.35.0,>=3.4.0->spacy-transformers) (0.18.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.venv/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/huggingface-hub/0.17.3/huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/mpmath/1.3.0/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, spacy-alignments, safetensors, regex, networkx, torch, huggingface-hub, tokenizers, transformers, spacy-transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.18.0\n",
      "    Uninstalling huggingface-hub-0.18.0:\n",
      "      Successfully uninstalled huggingface-hub-0.18.0\n",
      "Successfully installed huggingface-hub-0.17.3 mpmath-1.3.0 networkx-3.2 regex-2023.10.3 safetensors-0.4.0 spacy-alignments-0.9.1 spacy-transformers-1.3.2 sympy-1.12 tokenizers-0.14.1 torch-2.1.0 transformers-4.34.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Collecting span_marker\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/span-marker/1.4.0/span_marker-1.4.0-py3-none-any.whl (50 kB)\n",
      "Collecting accelerate\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/accelerate/0.23.0/accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "Requirement already satisfied: datasets>=2.14.0 in ./.venv/lib/python3.10/site-packages (from span_marker) (2.14.5)\n",
      "Collecting evaluate\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/evaluate/0.4.1/evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from span_marker) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from span_marker) (23.2)\n",
      "Requirement already satisfied: huggingface-hub in ./.venv/lib/python3.10/site-packages (from span_marker) (0.17.3)\n",
      "Requirement already satisfied: transformers>=4.19.0 in ./.venv/lib/python3.10/site-packages (from span_marker) (4.34.1)\n",
      "Collecting seqeval\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/seqeval/1.2.2/seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (from span_marker) (2.1.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (13.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (2.31.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (0.3.7)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (6.0.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (0.70.15)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (3.4.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (1.23.5)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in ./.venv/lib/python3.10/site-packages (from datasets>=2.14.0->span_marker) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub->span_marker) (4.8.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub->span_marker) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers>=4.19.0->span_marker) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./.venv/lib/python3.10/site-packages (from transformers>=4.19.0->span_marker) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.10/site-packages (from transformers>=4.19.0->span_marker) (0.4.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from accelerate->span_marker) (5.9.6)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch->span_marker) (3.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch->span_marker) (1.12)\n",
      "Collecting responses<0.19\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/responses/0.18.0/responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->span_marker) (2.1.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in ./.venv/lib/python3.10/site-packages (from seqeval->span_marker) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.0->span_marker) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.0->span_marker) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.0->span_marker) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.0->span_marker) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.0->span_marker) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.0->span_marker) (3.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.14.0->span_marker) (1.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.14.0->span_marker) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.14.0->span_marker) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.14.0->span_marker) (1.26.18)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->span_marker) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->span_marker) (1.11.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->span_marker) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets>=2.14.0->span_marker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets>=2.14.0->span_marker) (2023.3.post1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch->span_marker) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets>=2.14.0->span_marker) (1.16.0)\n",
      "Using legacy 'setup.py install' for seqeval, since package 'wheel' is not installed.\n",
      "Installing collected packages: responses, seqeval, accelerate, evaluate, span_marker\n",
      "  Running setup.py install for seqeval ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed accelerate-0.23.0 evaluate-0.4.1 responses-0.18.0 seqeval-1.2.2 span_marker-1.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Requirement already satisfied: soundfile in ./.venv/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: librosa in ./.venv/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.10/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in ./.venv/lib/python3.10/site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.venv/lib/python3.10/site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.venv/lib/python3.10/site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in ./.venv/lib/python3.10/site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: pooch>=1.0 in ./.venv/lib/python3.10/site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in ./.venv/lib/python3.10/site-packages (from librosa) (1.3.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.venv/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.10/site-packages (from librosa) (4.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.venv/lib/python3.10/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: joblib>=0.14 in ./.venv/lib/python3.10/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./.venv/lib/python3.10/site-packages (from librosa) (1.11.3)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in ./.venv/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from pooch>=1.0->librosa) (23.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.10/site-packages (from pooch>=1.0->librosa) (3.11.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Requirement already satisfied: deepsearch-toolkit in ./.venv/lib/python3.10/site-packages (0.29.1)\n",
      "Requirement already satisfied: six<2.0.0,>=1.16.0 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (1.16.0)\n",
      "Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (0.8.10)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.8 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (1.26.18)\n",
      "Requirement already satisfied: certifi<2024.0.0,>=2023.07.22 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (2023.7.22)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.27.1 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (2.31.0)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=3.5.1 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (3.11.0)\n",
      "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (2.8.2)\n",
      "Collecting typer[all]<0.10.0,>=0.9.0\n",
      "  Using cached https://dmrepository.datamaran.com:8443/repository/dmPYTHON/packages/typer/0.9.0/typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (4.66.1)\n",
      "Requirement already satisfied: pydantic[dotenv]<2.0.0,>=1.10.8 in ./.venv/lib/python3.10/site-packages (from deepsearch-toolkit) (1.10.13)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.10/site-packages (from pydantic[dotenv]<2.0.0,>=1.10.8->deepsearch-toolkit) (4.8.0)\n",
      "Requirement already satisfied: python-dotenv>=0.10.4 in ./.venv/lib/python3.10/site-packages (from pydantic[dotenv]<2.0.0,>=1.10.8->deepsearch-toolkit) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.27.1->deepsearch-toolkit) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.27.1->deepsearch-toolkit) (3.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.venv/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->deepsearch-toolkit) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in ./.venv/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->deepsearch-toolkit) (0.4.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in ./.venv/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->deepsearch-toolkit) (13.0.1)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in ./.venv/lib/python3.10/site-packages (from typer[all]<0.10.0,>=0.9.0->deepsearch-toolkit) (1.5.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in ./.venv/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->deepsearch-toolkit) (2.16.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in ./.venv/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->deepsearch-toolkit) (0.9.1)\n",
      "Installing collected packages: typer\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.7.0\n",
      "    Uninstalling typer-0.7.0:\n",
      "      Successfully uninstalled typer-0.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "argilla 1.17.0 requires typer<0.8.0,>=0.6.0, but you have typer 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typer-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
      "Collecting en-core-web-sm==3.7.0\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))': /explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./.venv/lib/python3.10/site-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.10.13)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (63.2.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./.venv/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install argilla==1.17 \n",
    "!pip install datasets\n",
    "!pip install spacy spacy-transformers\n",
    "!pip install Pillow\n",
    "!pip install span_marker\n",
    "!pip install soundfile librosa\n",
    "!pip install deepsearch-toolkit\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span_marker.spacy_integration.SpacySpanMarkerWrapper at 0x2bd635ea0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argilla as rg\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import span_marker\n",
    "from datasets import load_dataset\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\", \n",
    "    exclude=[\"ner\"]\n",
    ")\n",
    "nlp.add_pipe(\"span_marker\", config={\"model\": \"tomaarsen/span-marker-bert-tiny-fewnerd-coarse-super\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signup to Deep Search\n",
    "\n",
    "\n",
    "Go to https://deepsearch-experience.res.ibm.com/ and sign up for an account using the Google OAuth integration. Afterwards, you can use the following command to install the library.\n",
    "\n",
    "![authenticate](img/making-most-of-markdown/deepsearch.png)\n",
    "\n",
    "\n",
    "```bash\n",
    "deepsearch profile config --profile-name \"ds-experience\" --host \"https://deepsearch-experience.res.ibm.com/\" --verify-ssl --username \"<your-email>\"\n",
    "```\n",
    "\n",
    "And add `your-api-key` to the prompted terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Coding\n",
    "\n",
    "### Exploiting `displacy`\n",
    "\n",
    "Displacy is the library from spaCy that allows you to visualize the output of the NLP models. It is a very powerful tool, and we will be using it to visualize the output of the NER model. To do so, we will be using the `displacy.render` function, which takes in the text and the output of the NER model, and returns a HTML string that can be rendered within Argilla.\n",
    "\n",
    "Displacy can render dependencies, named entities, and even relationships. We will be using the first two, but if you want to learn more about displacy, you can check out the [documentation](https://spacy.io/usage/visualizers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b8063dbdb60743599f89fd11ea276b51-0\" class=\"displacy\" width=\"1450\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Rats</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">various</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">medium-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">sized,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">long-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">tailed</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">rodents.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8063dbdb60743599f89fd11ea276b51-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8063dbdb60743599f89fd11ea276b51-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8063dbdb60743599f89fd11ea276b51-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8063dbdb60743599f89fd11ea276b51-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8063dbdb60743599f89fd11ea276b51-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8063dbdb60743599f89fd11ea276b51-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8063dbdb60743599f89fd11ea276b51-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8063dbdb60743599f89fd11ea276b51-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8063dbdb60743599f89fd11ea276b51-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8063dbdb60743599f89fd11ea276b51-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8063dbdb60743599f89fd11ea276b51-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8063dbdb60743599f89fd11ea276b51-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b8063dbdb60743599f89fd11ea276b51-0-6\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1275.0,2.0 1275.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b8063dbdb60743599f89fd11ea276b51-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,354.0 L1283.0,342.0 1267.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Rats are various medium-sized, long-tailed rodents.\")\n",
    "x = displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">person</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">organization</span>\n",
       "</mark>\n",
       " in 2007, few people outside of the company took him seriously.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
    "doc2 = nlp(text)\n",
    "displacy.render(doc2, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create an Argilla `FeedbackDataset` and add the displacy output to it. We will be using the `FeedbackDataset` to render the displacy output. We will now configure it to show the default text, dependencies and entities. Additionally, we add some label questions to indicate whether the text is relevant, and the dependency parsing and named entities are correct. Also, we will be adding questions to assess whether the user want to apply a correction to the dependencies and/or entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ds = rg.FeedbackDataset(\n",
    "        fields=[\n",
    "            rg.TextField(name=\"text\", use_markdown=True),\n",
    "            rg.TextField(name=\"dep\", use_markdown=True),\n",
    "            rg.TextField(name=\"ent\", use_markdown=True)\n",
    "        ],\n",
    "        questions=[\n",
    "            rg.LabelQuestion(name=\"relevant\", labels=[\"yes\", \"no\"]),\n",
    "            rg.MultiLabelQuestion(name=\"question-multi\", labels=[\"flag-pos\", \"flag-ner\"]),\n",
    "            rg.TextQuestion(name=\"dep-correction\", use_markdown=True),\n",
    "            rg.TextQuestion(name=\"ner-correction\", use_markdown=True)\n",
    "        ]\n",
    "    )\n",
    "    ds = ds.push_to_argilla(\"exploiting-displacy\")\n",
    "except Exception as e:\n",
    "    ds = rg.FeedbackDataset.from_argilla(\"exploiting-displacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load the basic [few-nerd dataset from Hugging Face](https://huggingface.co/datasets/DFKI-SLT/few-nerd). This dataset contains a few sentences, and the output of the NER model. We will be using this dataset to show how to use displacy within Argilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fewnerd = load_dataset(\"DFKI-SLT/few-nerd\", \"supervised\", split=\"train[:10]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use this dataset to populate our Argilla `FeedbackDataset`. We will be using the `displacy.render` function to render the displacy output as html, and add it to the `FeedbackDataset`. We will also add the text, and the output of the NER model to the `FeedbackDataset`. Finally, we will also add markdown formatted tables to support basic support for NER and dependency annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing records to Argilla...: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\" \".join(x[\"tokens\"]) for x in dataset_fewnerd]\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "def wrap_in_max_width(html):\n",
    "    html = html.replace(\"max-width: none;\", \"\")\n",
    "    # remove existing width and height setting based on regex width=\"/d\"\n",
    "    html = re.sub(r\"width=\\\"\\d+\\\"\", \"overflow-x: auto;\", html)\n",
    "    html = re.sub(r\"height=\\\"\\d+\\\"\", \"\", html)\n",
    "    \n",
    "    # Find the SVG element in the HTML output\n",
    "    svg_start = html.find(\"<svg\")\n",
    "    svg_end = html.find(\"</svg>\") + len(\"</svg>\")\n",
    "    svg = html[svg_start:svg_end]\n",
    "\n",
    "    # Set the width and height attributes of the SVG element to 100%\n",
    "    svg = svg.replace(\"<svg\", \"<svg width='100%' height='100%'\")\n",
    "\n",
    "    # Wrap the SVG element in a div with max-width and horizontal scrolling\n",
    "    return f\"<div style='max-width: 100%; overflow-x: auto;'>{svg}</div>\"\n",
    "\n",
    "records = []\n",
    "for doc in docs:\n",
    "    record = rg.FeedbackRecord(\n",
    "        fields={\n",
    "            \"text\": doc.text, \n",
    "            \"dep\": wrap_in_max_width(displacy.render(doc, style=\"dep\", jupyter=False)), \n",
    "            \"ent\": displacy.render(doc, style=\"ent\", jupyter=False)\n",
    "        },\n",
    "        suggestions=[{\n",
    "                \"question_name\": \"dep-correction\", \n",
    "                \"value\": pd.DataFrame([{\"Label\": token.dep_, \"Text\": token.text} for token in doc]).to_markdown(index=False)\n",
    "\n",
    "            },\n",
    "            {\n",
    "                \"question_name\": \"ner-correction\", \n",
    "                \"value\": pd.DataFrame([{\"Label\": ent.label_, \"Text\": ent.text} for ent in doc.ents]).to_markdown(index=False),\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    records.append(record)\n",
    "ds.add_records(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Modality\n",
    "\n",
    "Yes, Argilla can work with images, video and audio, when formatted as HTML and used within a markdown field. However, besides using publicly available sources to do this, we can also us something called DataURLs. \n",
    "\n",
    "#### DataURLs\n",
    "\n",
    "A DataURL is a way to encode binary data into a string, which can then be used to embed the data into a webpage. This is a very useful tool, as it allows us to embed images, videos, and audio files directly into html, without having to worry about hosting them externally. This is done by prepending the data with a header, which specifies the type of data being encoded, and the encoding used. We will define three different functions, one for each modality, which will take a file path as input, and return a DataURL as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "def get_file_type(path):\n",
    "    return Path(path).suffix[1:]\n",
    "\n",
    "def video_to_dataurl(path, file_type: str = None):\n",
    "    # Open the video file and read its contents\n",
    "    with open(path, 'rb') as f:\n",
    "        video_data = f.read()\n",
    "\n",
    "    # Encode the video data as base64\n",
    "    video_base64 = base64.b64encode(video_data).decode('utf-8')\n",
    "\n",
    "    # Get the file type (e.g. mp4)\n",
    "    file_type = file_type or get_file_type(path)\n",
    "    \n",
    "    # Prepend the Data URL prefix to the base64-encoded data\n",
    "    data_url = f'data:video/{file_type};base64,' + video_base64\n",
    "\n",
    "    # Create HTML\n",
    "    html = f\"<video controls><source src='{data_url}' type='video/{file_type}'></video>\"\n",
    "    return html\n",
    "    \n",
    "def audio_to_dataurl(path, file_type: str = None):\n",
    "    # Open the audio file and read its contents\n",
    "    with open(path, 'rb') as f:\n",
    "        audio_data = f.read()\n",
    "    \n",
    "    # Encode the audio data as base64\n",
    "    audio_base64 = base64.b64encode(audio_data).decode('utf-8')\n",
    "    \n",
    "    # Get the file type (e.g. mp3)\n",
    "    file_type = file_type or get_file_type(path)\n",
    "    \n",
    "    # Prepend the Data URL prefix to the base64-encoded data\n",
    "    data_url = f'data:audio/{file_type};base64,' + audio_base64\n",
    "    \n",
    "    # Create HTML\n",
    "    html = f\"<audio controls autoplay><source src='{data_url}' type='audio/{file_type}'></audio>\"\n",
    "    return html\n",
    "\n",
    "def image_to_dataurl(path, content, file_type: str = None):\n",
    "    # open the image file and read its contents\n",
    "    with open(path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "        \n",
    "    # Encode the image data as base64\n",
    "    image_base64 = base64.b64encode(image_data).decode('utf-8')\n",
    "    \n",
    "    # Get the file type (e.g. png)\n",
    "    file_type = file_type or get_file_type(path)\n",
    "    \n",
    "    # Prepend the Data URL prefix to the base64-encoded data\n",
    "    data_url = f'data:image/{file_type};base64,' + image_base64\n",
    "    \n",
    "    # Create HTML\n",
    "    html = f'<img src=\"{data_url}\">'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define our `FeedbackDataset` and add the DataURLs to it. We will also add a question to ask the user to describe the image, video, or audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ds = rg.FeedbackDataset(\n",
    "        fields=[rg.TextField(name=\"content\", use_markdown=True)],\n",
    "        questions=[rg.TextQuestion(name=\"describe\")],\n",
    "    )\n",
    "    ds = ds.push_to_argilla(\"multi-modal\")\n",
    "    \n",
    "except:\n",
    "    ds = rg.FeedbackDataset.from_argilla(\"multi-modal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add the DataURLs to the `add_records`-method. We will also add a question to ask the user to describe the image, video, or audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "records = [\n",
    "    rg.FeedbackRecord(fields={\"content\": audio_to_dataurl(\"img/making-most-of-markdown/heath_ledger.mp3\")}),\n",
    "    rg.FeedbackRecord(fields={\"content\": audio_to_dataurl(\"img/making-most-of-markdown/heath_ledger_2.mp3\")}),\n",
    "    rg.FeedbackRecord(fields={\"content\": image_to_dataurl(\"img/making-most-of-markdown/deepsearch.png\")}),\n",
    "    rg.FeedbackRecord(fields={\"content\": video_to_dataurl(\"img/making-most-of-markdown/snapshot.mp4\")})\n",
    "]\n",
    "ds.add_records(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create proper datasets\n",
    "\n",
    "##### For Audio Classification\n",
    "\n",
    "For this example audio classification dataset, we will be using the [ccmusic-database/bel_folk](https://huggingface.co/datasets/ccmusic-database/bel_folk) dataset from Hugging Face. This dataset contains 1 minute audio clips of Chinese folk music, and the genre of the music. We will be using this dataset to create a dataset for audio classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'audio': {'path': '/Users/davidberenstein/.cache/huggingface/datasets/downloads/extracted/16960b86c4c6c0594ad82b11290ee5a7bb8f111068e9c6032444a2005fe715ad/dataset/audio/folk_f (39).wav',\n",
       "   'array': array([-0.00036986, -0.00120128, -0.00222397, ...,  0.00090062,\n",
       "           0.00168412,  0.0010872 ]),\n",
       "   'sampling_rate': 44100},\n",
       "  'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=476x349>,\n",
       "  'label': 3,\n",
       "  'gender': 0,\n",
       "  'singing_method': 0},\n",
       " {'audio': Audio(sampling_rate=44100, mono=True, decode=True, id=None),\n",
       "  'image': Image(decode=True, id=None),\n",
       "  'label': ClassLabel(names=['m_bel', 'f_bel', 'm_folk', 'f_folk'], id=None),\n",
       "  'gender': ClassLabel(names=['female', 'male'], id=None),\n",
       "  'singing_method': ClassLabel(names=['Folk Singing', 'Bel Canto'], id=None)})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "my_audio_dataset = load_dataset(\"ccmusic-database/bel_folk\")\n",
    "my_audio_dataset = my_audio_dataset.shuffle()\n",
    "my_audio_dataset[\"train\"][0], my_audio_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define `label`, `gender`, `singing_method` columns as `LabelQeustion` columns and infer the label sets from the `Datasets.features` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteFeedbackDataset(\n",
       "   id=8005e3b0-c932-462a-8f49-d0acb0044e2e\n",
       "   name=audio\n",
       "   workspace=Workspace(id=268dbd87-2970-46cd-a84a-e3785b7178b7, name=argilla, inserted_at=2023-08-14 13:02:15, updated_at=2023-08-14 13:02:15)\n",
       "   url=http://localhost:6900/dataset/8005e3b0-c932-462a-8f49-d0acb0044e2e/annotation-mode\n",
       "   fields=[RemoteTextField(id=UUID('16121a5f-a9b3-4a59-92cb-eebdbcbeb957'), client=None, name='audio', title='Audio', required=True, type='text', use_markdown=True)]\n",
       "   questions=[RemoteLabelQuestion(id=UUID('cf389c89-cf1e-416a-b7da-5f59838cf1d3'), client=None, name='general', title='General', description=None, required=True, type='label_selection', labels=['m_bel', 'f_bel', 'm_folk', 'f_folk'], visible_labels=None), RemoteLabelQuestion(id=UUID('08edc7e7-b8c2-41b3-8526-b9ae04fa15f5'), client=None, name='gender', title='Gender', description=None, required=True, type='label_selection', labels=['female', 'male'], visible_labels=None), RemoteLabelQuestion(id=UUID('54e321b7-7a6c-4df7-8c35-29aac6aa3dfe'), client=None, name='singing_method', title='Singing_method', description=None, required=True, type='label_selection', labels=['Folk Singing', 'Bel Canto'], visible_labels=None)]\n",
       "   guidelines=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_general = my_audio_dataset[\"train\"].features[\"label\"].names\n",
    "label_gender = my_audio_dataset[\"train\"].features[\"gender\"].names\n",
    "label_singing_method = my_audio_dataset[\"train\"].features[\"singing_method\"].names\n",
    "rg_ds_audio = rg.FeedbackDataset(\n",
    "    fields=[rg.TextField(name=\"audio\", use_markdown=True)],\n",
    "    questions=[\n",
    "        rg.LabelQuestion(name=\"general\", labels=label_general),\n",
    "        rg.LabelQuestion(name=\"gender\", labels=label_gender),\n",
    "        rg.LabelQuestion(name=\"singing_method\", labels=label_singing_method)\n",
    "    ]\n",
    ")\n",
    "try:\n",
    "    rg_ds_audio = rg.FeedbackDataset.from_argilla(\"audio\")\n",
    "except:\n",
    "    rg_ds_audio = rg_ds_audio.push_to_argilla(\"audio\")\n",
    "rg_ds_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define our `FeedbackDataset` and add the DataURLs to it by using the b64encode function `audio_to_dataurl`. Also, we will be adding dataset suggestions for each one of the label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too large\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "my_audio_dataset_slice = my_audio_dataset[\"train\"].select(range(20))\n",
    "for entry in my_audio_dataset_slice:\n",
    "    record = rg.FeedbackRecord(\n",
    "        fields={\"audio\": audio_to_dataurl(entry[\"audio\"][\"path\"])},\n",
    "        suggestions=[\n",
    "            {\"question_name\": \"general\", \"value\": label_general[entry[\"label\"]]},\n",
    "            {\"question_name\": \"gender\", \"value\": label_gender[entry[\"gender\"]]},\n",
    "            {\"question_name\": \"singing_method\", \"value\": label_singing_method[entry[\"singing_method\"]]}\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        rg_ds_audio.add_records(record, show_progress=False)\n",
    "    except:\n",
    "        print(\"too large\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Image Classification \n",
    "\n",
    "Within this example, we will be using the [zishuod/pokemon-icons](https://huggingface.co/datasets/\"zishuod/pokemon-icons\") dataset from Hugging Face. This dataset contains images of Pokemon that need to be classified. We will be using this dataset to create a dataset for image classification but feel free to use any other image classification dataset listed below.\n",
    "\n",
    "Some examples are:\n",
    "- \"zishuod/pokemon-icons\"\n",
    "- \"keremberke/shoe-classification\"\n",
    "- \"sampath017/plants\"\n",
    "- \"sin3142/memes-500\"\n",
    "- \"adamkatav/mtg_subsample\"\n",
    "- \"sxdave/emotion_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e45adc9e8a84e5ba32b8a2173bcd39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac86c0c1a8644c58d414623bfe45ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=75x75>,\n",
       "  'label': 70},\n",
       " {'image': Image(decode=True, id=None),\n",
       "  'label': ClassLabel(names=['aegislash', 'amoonguss', 'arcanine', 'azumarill', 'blastoise', 'blaziken', 'blissey', 'calyrex', 'celesteela', 'centiskorch', 'chansey', 'charizard', 'cinderace', 'clefable', 'clefairy', 'coalossal', 'comfey', 'cresselia', 'darmanitan', 'dialga', 'diggersby', 'dracovish', 'dracozolt', 'dragapult', 'drifblim', 'durant', 'dusclops', 'eternatus', 'excadrill', 'ferrothorn', 'garchomp', 'gastrodon', 'gigalith', 'glastrier', 'gothitelle', 'grimmsnarl', 'groudon', 'gyarados', 'heatran', 'hippowdon', 'hooh', 'hydreigon', 'incineroar', 'indeedee', 'kartana', 'kyogre', 'landorus', 'lapras', 'ludicolo', 'mamoswine', 'metagross', 'mewtwo', 'mienshao', 'milotic', 'mimikyu', 'moltres', 'necrozma', 'nihilego', 'ninetales', 'pheromosa', 'pikachu', 'porygon2', 'primarina', 'quagsire', 'raichu', 'raikou', 'regieleki', 'regigigas', 'registeel', 'rhyperior', 'rillaboom', 'rotom', 'sableye', 'scrafty', 'shedinja', 'skarmory', 'solgaleo', 'spectrier', 'stakataka', 'stoutland', 'sylveon', 'talonflame', 'tapufini', 'tapulele', 'thundurus', 'togedemaru', 'togekiss', 'torkoal', 'tornadus', 'toxapex', 'tyranitar', 'umbreon', 'urshifu', 'venusaur', 'weezing', 'whimsicott', 'xerneas', 'yveltal', 'zacian', 'zapdos', 'zekrom', 'zygarde'], id=None)})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_image_dataset  = load_dataset(\"zishuod/pokemon-icons\")\n",
    "my_image_dataset = my_image_dataset.shuffle()\n",
    "my_image_dataset[\"train\"][0], my_image_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define `label` column as `LabelQeustion` columns and infer the label sets from the `Datasets.features` attribute. Also, we will use a basic `TextField` to add the image to the `FeedbackDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidberenstein/Documents/programming/argilla/argilla-workshop/.venv/lib/python3.10/site-packages/argilla/client/feedback/schemas/questions.py:170: UserWarning: Since `visible_labels` has not been provided and the total number of labels is greater than 20, `visible_labels` will be set to `20`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RemoteFeedbackDataset(\n",
       "   id=c29c5a97-eb64-49d9-a57e-ec0a5f6e6038\n",
       "   name=image\n",
       "   workspace=Workspace(id=268dbd87-2970-46cd-a84a-e3785b7178b7, name=argilla, inserted_at=2023-08-14 13:02:15, updated_at=2023-08-14 13:02:15)\n",
       "   url=http://localhost:6900/dataset/c29c5a97-eb64-49d9-a57e-ec0a5f6e6038/annotation-mode\n",
       "   fields=[RemoteTextField(id=UUID('80f85ff4-052a-4e11-aec0-93e63857fcc2'), client=None, name='image', title='Image', required=True, type='text', use_markdown=True)]\n",
       "   questions=[RemoteLabelQuestion(id=UUID('81d57bd8-f69b-48fa-83cd-90fb805acd84'), client=None, name='label', title='Label', description=None, required=True, type='label_selection', labels=['aegislash', 'amoonguss', 'arcanine', 'azumarill', 'blastoise', 'blaziken', 'blissey', 'calyrex', 'celesteela', 'centiskorch', 'chansey', 'charizard', 'cinderace', 'clefable', 'clefairy', 'coalossal', 'comfey', 'cresselia', 'darmanitan', 'dialga', 'diggersby', 'dracovish', 'dracozolt', 'dragapult', 'drifblim', 'durant', 'dusclops', 'eternatus', 'excadrill', 'ferrothorn', 'garchomp', 'gastrodon', 'gigalith', 'glastrier', 'gothitelle', 'grimmsnarl', 'groudon', 'gyarados', 'heatran', 'hippowdon', 'hooh', 'hydreigon', 'incineroar', 'indeedee', 'kartana', 'kyogre', 'landorus', 'lapras', 'ludicolo', 'mamoswine', 'metagross', 'mewtwo', 'mienshao', 'milotic', 'mimikyu', 'moltres', 'necrozma', 'nihilego', 'ninetales', 'pheromosa', 'pikachu', 'porygon2', 'primarina', 'quagsire', 'raichu', 'raikou', 'regieleki', 'regigigas', 'registeel', 'rhyperior', 'rillaboom', 'rotom', 'sableye', 'scrafty', 'shedinja', 'skarmory', 'solgaleo', 'spectrier', 'stakataka', 'stoutland', 'sylveon', 'talonflame', 'tapufini', 'tapulele', 'thundurus', 'togedemaru', 'togekiss', 'torkoal', 'tornadus', 'toxapex', 'tyranitar', 'umbreon', 'urshifu', 'venusaur', 'weezing', 'whimsicott', 'xerneas', 'yveltal', 'zacian', 'zapdos', 'zekrom', 'zygarde'], visible_labels=20)]\n",
       "   guidelines=None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_image = my_image_dataset[\"train\"].features[\"label\"].names\n",
    "rg_ds_image = rg.FeedbackDataset(\n",
    "    fields=[rg.TextField(name=\"image\", use_markdown=True)],\n",
    "    questions=[rg.LabelQuestion(name=\"label\", labels=label)]\n",
    ")\n",
    "try:\n",
    "    rg_ds_image = rg.FeedbackDataset.from_argilla(\"image\")\n",
    "except:\n",
    "    rg_ds_image = rg_ds_image.push_to_argilla(\"image\")\n",
    "rg_ds_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define our `FeedbackDataset` and add the DataURLs to it by using the b64encode function `image_to_dataurl`. Also, we will be adding dataset suggestions for each one of the label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_img_path = \"data/making-most-of-markdown/temp_img.png\"\n",
    "records = []\n",
    "for entry in my_image_dataset[\"train\"]:\n",
    "    entry[\"image\"].save(temp_img_path, format=\"png\")\n",
    "    record = rg.FeedbackRecord(\n",
    "        fields={\"image\": image_to_dataurl(temp_img_path, file_type=\"png\")},\n",
    "        suggestions=[{\"question_name\": \"label\", \"value\": label_image[entry[\"label\"]]}]\n",
    "    )\n",
    "    try:\n",
    "        rg_ds_image.add_records(record, show_progress=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"too large\")\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
